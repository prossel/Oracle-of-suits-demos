<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>MediaPipe Hand Gesture â€” trained classifier</title>

  <link rel="stylesheet" type="text/css" href="style.css">

  <script src="../libraries/p5.min.js"></script>
  <script src="../libraries/p5.sound.min.js"></script>
</head>

<body>
  <!-- container where the p5 canvas will be inserted -->
  <div id="canvas-container"></div>

  <script type="module" src="sketch.js"></script>

  <div id="summary" class="summary" aria-live="polite">
    <strong>About this starter</strong>
    <p>This starter uses MediaPipe Hands to detect hand landmarks and demonstrates using a custom/trained gesture classifier.
       It shows how to map model outputs to friendly gesture names; the detected gesture name is displayed near the top of the canvas for each hand.
    </p>
    <p>Shortcut: press V to toggle video</p>
  </div>
</body>

</html>
